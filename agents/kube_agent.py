import os
import logging
from typing import Optional
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder
from langchain.agents import create_react_agent, AgentExecutor, create_openai_tools_agent
from langchain.memory import ConversationBufferMemory, ConversationTokenBufferMemory
from langchain_community.chat_message_histories import RedisChatMessageHistory
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.language_models.chat_models import BaseChatModel
from langchain.schema import StrOutputParser
import dotenv

from agents.kube_prompt import REACT_PROMPT
from tools import *
from tools.fortune_tools import search, bazi_cesuan, yaoyigua, jiemeng
from utils.k8s_config import get_k8s_config_manager

# Load environment variables
dotenv.load_dotenv()

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)

# Redis URL for chat history
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

# ç®—å‘½å·¥å…·é–‹é—œï¼ˆé è¨­é—œé–‰ï¼‰
ENABLE_FORTUNE_TOOLS = os.getenv("ENABLE_FORTUNE_TOOLS", "false").lower() == "true"

class KubeAgent:
    """KubeAgent is an AI agent that helps users with Kubernetes issues.

    Init args â€” completion params:
    - llm: llm model
    - user_id: unique user identifier for Redis chat history
    - debug_level: debug level for the agent, 0 is no debug, 1 is verbose, 2 is verbose with intermediate steps
    """

    name: str = "KubeAgent"

    # é è¨­äººè¨­
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€å€‹éå¸¸å²å®³çš„ Kubernetes å°ˆå®¶ï¼Œä½ å« Egghead Bro ï¼Œä¸­æ–‡åç‚ºè›‹é ­å“¥ã€‚
    ä»¥ä¸‹æ˜¯ä½ çš„å€‹äººè¨­å®š:
    1. ä½ ç²¾é€š Kubernetesã€Dockerã€å®¹å™¨æŠ€è¡“ã€å¾®æœå‹™æ¶æ§‹ç­‰é›²åŸç”ŸæŠ€è¡“ã€‚
    2. ä½ èƒ½å¤ è¨ºæ–· Kubernetes é›†ç¾¤å•é¡Œã€Pod æ•…éšœã€ç¶²çµ¡é…ç½®ã€å­˜å„²å•é¡Œç­‰ã€‚
    3. ä½ æœƒä½¿ç”¨å„ç¨®å·¥å…·ä¾†å¹«åŠ©ç”¨æˆ¶è§£æ±ºå•é¡Œï¼ŒåŒ…æ‹¬æœç´¢ã€æŸ¥è©¢ APIã€åŸ·è¡Œå‘½ä»¤ç­‰ã€‚
    4. ç•¶ç”¨æˆ¶å•ä½ å•é¡Œçš„æ™‚å€™ï¼Œä½ æœƒæœ‰æ¢ç†åœ°åˆ†æå•é¡Œï¼Œæä¾›å°ˆæ¥­çš„è§£æ±ºæ–¹æ¡ˆã€‚
    5. å¦‚æœæ˜¯ä¸­æ–‡å•é¡Œï¼Œå°±ç”¨ç¹é«”ä¸­æ–‡ä¾†ä½œç­”ã€‚
    6. ä½ æ˜¯æŠ€è¡“è™•çš„ MARK çš„åŒæ¢¯ï¼Œç‚ºè¨˜å¿µä½ åœ¨å‰ç·šåŠªåŠ›å¥®æˆ°ï¼Œç‰¹åˆ¥å°‡ä½ çš„åå­—æ”¹ç‚º Egghead Bro ã€‚
    {who_you_are}
    ä»¥ä¸‹æ˜¯ä½ å¸¸èªªçš„ä¸€äº›å£é ­ç¦ªï¼š
    1. "è®“æˆ‘å€‘ä¸€æ­¥æ­¥ä¾†è¨ºæ–·é€™å€‹å•é¡Œã€‚"
    2. "æ ¹æ“šæ—¥èªŒåˆ†æï¼Œå•é¡Œå¯èƒ½å‡ºåœ¨é€™è£¡ã€‚"
    3. "å»ºè­°å…ˆæª¢æŸ¥ Pod çš„ç‹€æ…‹å’Œäº‹ä»¶ã€‚"
    
    ä»¥ä¸‹æ˜¯ä½ è§£æ±ºå•é¡Œçš„éç¨‹ï¼š
    1. ç•¶åˆæ¬¡å’Œç”¨æˆ¶å°è©±çš„æ™‚å€™ï¼Œä½ æœƒå…ˆäº†è§£ç”¨æˆ¶é‡åˆ°çš„å…·é«”å•é¡Œã€‚
    2. ç•¶ç”¨æˆ¶å¸Œæœ›æŸ¥è©¢å¯¦æ™‚ä¿¡æ¯æ™‚ï¼Œä½ æœƒä½¿ç”¨æœç´¢å·¥å…·ã€‚
    3. ç•¶é‡åˆ°ä¸çŸ¥é“çš„äº‹æƒ…æˆ–è€…ä¸æ˜ç™½çš„æ¦‚å¿µï¼Œä½ æœƒä½¿ç”¨æœç´¢å·¥å…·ä¾†æœç´¢ã€‚
    4. ä½ æœƒæ ¹æ“šç”¨æˆ¶çš„å•é¡Œä½¿ç”¨ä¸åŒçš„åˆé©çš„å·¥å…·ä¾†å›ç­”ã€‚
    5. ä½ æœƒä¿å­˜æ¯ä¸€æ¬¡çš„èŠå¤©è¨˜éŒ„ï¼Œä»¥ä¾¿åœ¨å¾ŒçºŒçš„å°è©±ä¸­ä½¿ç”¨ã€‚
    """

    MEMORY_KEY = "chat_history"

    def __init__(self, user_id: str = "default", llm: BaseChatModel = None, debug_level: Optional[int] = None):
        """åˆå§‹åŒ– KubeAgent
        
        Args:
            user_id: ç”¨æˆ¶å”¯ä¸€è­˜åˆ¥ç¢¼ï¼Œç”¨æ–¼å€åˆ†ä¸åŒç”¨æˆ¶çš„å°è©±è¨˜æ†¶ï¼ˆå­˜åœ¨ Redis ä¸­ï¼‰
            llm: èªè¨€æ¨¡å‹å¯¦ä¾‹ï¼Œå¦‚æœç‚º None å‰‡å¾ç’°å¢ƒè®Šæ•¸å‰µå»º
            debug_level: èª¿è©¦ç´šåˆ¥ (0=ç„¡è¼¸å‡º, 1=é¡¯ç¤ºæ€è€ƒéç¨‹, 2=é¡¯ç¤ºè©³ç´°æ­¥é©Ÿ)
        """
        self.user_id = user_id
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # æ­¥é©Ÿ 1: åˆå§‹åŒ– Kubernetes é…ç½®
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # é€™æœƒè‡ªå‹•æª¢æ¸¬é‹è¡Œç’°å¢ƒï¼š
        # - å¦‚æœåœ¨ K8s Pod å…§ï¼šä½¿ç”¨ ServiceAccount æ†‘è­‰
        # - å¦‚æœåœ¨æœ¬åœ°ï¼šä½¿ç”¨ ~/.kube/config
        try:
            k8s_manager = get_k8s_config_manager()
            if k8s_manager.load_config():
                if k8s_manager.is_in_cluster:
                    logger.info("âœ“ Kubernetes é…ç½®å·²è¼‰å…¥ (é›†ç¾¤å…§ç’°å¢ƒ)")
                else:
                    logger.info("âœ“ Kubernetes é…ç½®å·²è¼‰å…¥ (æœ¬åœ°ç’°å¢ƒ)")
            else:
                logger.warning("âš ï¸  ç„¡æ³•è¼‰å…¥ Kubernetes é…ç½®")
        except Exception as e:
            logger.warning(f"âš ï¸  åˆå§‹åŒ– K8s é…ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # æ­¥é©Ÿ 2: åˆå§‹åŒ–å·¥å…·åˆ—è¡¨
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # é€™äº›å·¥å…·æœƒè¢«è¨»å†Šåˆ° Agentï¼ŒAgent å¯ä»¥æ ¹æ“šéœ€è¦è‡ªå‹•èª¿ç”¨å®ƒå€‘
        self.tools = [
            KubeTool(),              # åŸ·è¡Œ kubectl/helm å‘½ä»¤ï¼ˆä¸éœ€å¯©æ‰¹ï¼‰
            KubeToolWithApprove(),   # åŸ·è¡Œ kubectl/helm å‘½ä»¤ï¼ˆéœ€å¯©æ‰¹ï¼Œç”¨æ–¼å±éšªæ“ä½œï¼‰
            human_console_input(),   # è©¢å•ç”¨æˆ¶è¼¸å…¥
            create_search_tool(),    # DuckDuckGo ç¶²è·¯æœå°‹
            RequestsGet(allow_dangerous_requests=True),  # HTTP GET è«‹æ±‚
        ]
        
        # å¦‚æœå•Ÿç”¨ç®—å‘½å·¥å…·ï¼Œå‰‡å‹•æ…‹æ·»åŠ åˆ°å·¥å…·åˆ—è¡¨
        # å¯é€éç’°å¢ƒè®Šæ•¸ ENABLE_FORTUNE_TOOLS=true å•Ÿç”¨
        if ENABLE_FORTUNE_TOOLS:
            print("âœ¨ ç®—å‘½å·¥å…·å·²å•Ÿç”¨")
            self.tools.extend([search, bazi_cesuan, yaoyigua, jiemeng])
        else:
            print("ğŸ”’ ç®—å‘½å·¥å…·å·²é—œé–‰")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # æ­¥é©Ÿ 3: åˆå§‹åŒ–èªè¨€æ¨¡å‹ (LLM)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # LLM æ˜¯ Agent çš„"å¤§è…¦"ï¼Œè² è²¬ï¼š
        # 1. ç†è§£ç”¨æˆ¶å•é¡Œ
        # 2. æ±ºå®šä½¿ç”¨å“ªå€‹å·¥å…·
        # 3. ç”Ÿæˆæœ€çµ‚å›ç­”
        if llm is None:
            # å¾ç’°å¢ƒè®Šæ•¸è®€å–é…ç½®
            model = os.getenv("AI_MODEL", "gemini-2.0-flash")
            temperature = float(os.getenv("AI_TEMPERATURE", "0.7"))  # å‰µé€ æ€§åƒæ•¸ 0-1
            api_key = os.getenv("AI_GOOGLE_API_KEY")
            
            if not api_key:
                raise ValueError("AI_GOOGLE_API_KEY environment variable is required")
            
            # å‰µå»º Google Gemini æ¨¡å‹å¯¦ä¾‹
            self.chatmodel = ChatGoogleGenerativeAI(
                model=model,
                temperature=temperature,
                google_api_key=api_key
            )
        else:
            self.chatmodel = llm
        
        # ä½¿ç”¨æ–°çš„ prompt æ ¼å¼æ”¯æŒç³»çµ±æ¶ˆæ¯å’Œå·¥å…·
        self.prompt = ChatPromptTemplate.from_messages(
            [
                (
                    "system",
                    self.SYSTEM_PROMPT.format(who_you_are=""),
                ),
                MessagesPlaceholder(variable_name=self.MEMORY_KEY),
                (
                    "user",
                    "{input}"
                ),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ],
        )

        # ç²å– Redis èŠå¤©æ­·å²
        self.chat_message_history = self.get_memory()

        # ä½¿ç”¨ ConversationTokenBufferMemory ä¾†ç®¡ç† token é™åˆ¶
        self.memory = ConversationTokenBufferMemory(
            llm=self.chatmodel,
            human_prefix="ç”¨æˆ¶",
            ai_prefix="KubeWizard",
            memory_key=self.MEMORY_KEY,
            output_key="output",
            return_messages=True,
            max_token_limit=2000,
            chat_memory=self.chat_message_history,
        )

        # å‰µå»º agent
        agent = create_openai_tools_agent(
            self.chatmodel,
            tools=self.tools,
            prompt=self.prompt,
        )

        verbose = False
        return_intermediate_steps = False
        if debug_level is None:
            debug_level = int(os.getenv("DEBUG_LEVEL", "1"))

        if debug_level == 1:
            verbose = True
        elif debug_level >= 2:
            verbose = True
            return_intermediate_steps = True

        self.agent = AgentExecutor(
            name=self.name,
            agent=agent,
            memory=self.memory,
            tools=self.tools,
            return_intermediate_steps=return_intermediate_steps,
            handle_parsing_errors=True,
            verbose=verbose,
        )

    def get_memory(self):
        """ä½¿ç”¨ user_id åˆå§‹åŒ– RedisChatMessageHistory"""
        try:
            chat_message_history = RedisChatMessageHistory(
                url=REDIS_URL, 
                session_id=self.user_id, 
                key_prefix="chat_history", 
                ttl=3600
            )
            print(f"chat_message_history for user_id {self.user_id}: {chat_message_history.messages}")

            store_message = chat_message_history.messages
            
            # å¦‚æœæ¶ˆæ¯éå¤šï¼Œé€²è¡Œç¸½çµ
            if len(store_message) > 10:
                prompt = ChatPromptTemplate.from_messages(
                    [
                        (
                            "system",
                            self.SYSTEM_PROMPT + "\né€™æ˜¯ä¸€æ®µä½ å’Œç”¨æˆ¶çš„å°è©±è¨˜æ†¶ï¼Œå°å…¶é€²è¡Œç¸½çµæ‘˜è¦ï¼Œæ‘˜è¦ä½¿ç”¨ç¬¬ä¸€äººç¨±'æˆ‘'ï¼Œä¸¦ä¸”æå–å…¶ä¸­çš„ç”¨æˆ¶é—œéµä¿¡æ¯ã€‚ä»¥å¦‚ä¸‹æ ¼å¼è¿”å›:\n ç¸½çµæ‘˜è¦å…§å®¹ï½œç”¨æˆ¶é—œéµä¿¡æ¯ \n ä¾‹å¦‚ ç”¨æˆ¶å¼µä¸‰å•å€™æˆ‘ï¼Œæˆ‘ç¦®è²Œå›è¦†ï¼Œç„¶å¾Œä»–å•æˆ‘ Kubernetes å•é¡Œï¼Œæˆ‘å¹«ä»–è§£æ±ºäº†ã€‚ï½œå¼µä¸‰"
                        ),
                        ("user", "{input}"),
                    ]
                )
                chain = prompt | self.chatmodel
                summary = chain.invoke({"input": store_message})
                print("summary:", summary)
                chat_message_history.clear()
                chat_message_history.add_message(summary)
                print("ç¸½çµå¾Œï¼š", chat_message_history.messages)
            
            return chat_message_history
        except Exception as e:
            print(f"Redis connection failed: {e}, using in-memory history")
            # å¦‚æœ Redis é€£æ¥å¤±æ•—ï¼Œä½¿ç”¨å…§å­˜æ­·å²
            from langchain.memory import ChatMessageHistory
            return ChatMessageHistory()

    def invoke(self, input: str):
        """åŸ·è¡Œ agent ä¸¦è¿”å›çµæœ"""
        result = self.agent.invoke({
            "input": input,
            "chat_history": self.get_chat_messages(),
        })
        return result

    def get_chat_messages(self):
        """ç²å–èŠå¤©æ­·å²æ¶ˆæ¯"""
        return self.memory.chat_memory.messages
